\chapter{Background}

	To fully understand the issues involved in creating the Process Language 
	Runtime, a little background knowledge is required. First, Process 
	languages are explained, their history, common properties and practical 
	applications. Secondly, the .NET framework is presented and its technology
	explained.

\section{Process Languages}

\subsection{Overview and history}

	Process Languages, also known as Process Algebras or Process Calculi, are a
	family of languages to formally model concurrent systems. These languages 
	describe the systems at a high level of abstraction, as interactions, 
	communications, and synchronizations between a collection of independent
	processes. This is typically done using only a handful of constructs, many 
	of which are shared between different process languages, albeit 
	with different concrete syntax. These common constructs are explained 
	further in Section~\ref{common_constructs}. Some of the more prominent 
	process languages today include Calculus of Communicating Systems (CCS), 
	Communicating Sequential Processes (CSP), $\pi$-calculus and Kernel Language 
	for Agents Interaction and Mobility (KLAIM).
	
	Algebraic laws have been defined for these languages that allow process 
	descriptions or equations to be analyzed and manipulated, and permit formal 
	reasoning about equivalences between different processes, using for instance 
	bi-simulation. In this paper we do not focus on these algebraic properties 
	but instead concern ourselves with implementations of process algebras as 
	programming languages. For those interested, a good explanation of the 
	algebra involved in one such language, CCS, can be found in \cite{reactive}.
	
	Two of the most important figures in the history of process algebras are 
	Robert Milner and C.A.R. Hoare. Milner published a number of papers 
	\cite{milner1,milner2,milner3} throughout the 1970's about concurrency and 
	possible formal semantics for 
	analyzing concurrent systems. In 1980 he published \cite{Milner80} which 
	introduced \textit{Calculus of Communicating Systems}. He continued working 
	on concurrent systems and in 1989 published \cite{Milner89acalculus} which 
	introduced $\pi$\textit{-calculus}, a successor to CCS. Hoare started 
	working on process algebras at a similar time and in 1978 published 
	\cite{csp} where he introduced \textit{Communicating Sequential Processes} 
	or CSP. These two algebras, CCS and CSP, have become the basis on which much 
	of the later work in this field derives from. Both Milner and Hoare have 
	continued working with concurrent systems and have published a number of 
	papers refining and further extending CCS and CSP.
	
	Practical applications of process algebra are many. They have been used to 
	model real world systems, verify absence of deadlocks and break 
	cryptographic protocols to name a few. They have also influenced a number of 
	mainstream programming languages. One example is the Erlang programming 
	language. It was developed by the Ericsson telecommunications company and 
	its main strength is concurrency. It has the notion of processes that 
	communicate through message passing, and the core language has been modelled 
	in $\pi$-calculus \cite{erlang}. Another example is the occam programming 
	language, which builds on CSP and occam-pi \cite{occampi} which incorporates 
	ideas from both CSP and $\pi$-calculus.
		
	
\subsection{Common constructs}\label{common_constructs}
	
	The syntax for the common constructs varies between different process 
	languages, in this section we shall use the syntax from Calculus of 
	Communicating Systems (CCS) to demonstrate the concepts behind the 
	constructs.
	
	\textbf{Parallel composition} is the key construct which separates process 
	algebra from sequential modes of computation. With parallel composition, two 
	or more processes can run independently of each other at the same time. 
	Parallel composition is typically represented with the $|$ character, so for 
	two parallel processes, $P$ and $Q$, we write $P\ |\ Q$ to indicate that 
	they run in parallel.

	\textbf{A null process} is a process that does nothing and cannot interact 
	with any other processes. It has different representations in different 
	algebras, common symbols for it include \textbf{nil}, \textbf{0} and 
	\textbf{STOP}. The purpose of the null process is to be an anchor upon which 
	more interesting processes can be generated. An usual pattern is for a 
	process is to first perform one or more actions and then turn into the null 
	process, which signifies that it has run its course.
	
	\textbf{Message passing through channels} is the way processes interact with 
	each other. One process sends an outbound message on a particular named 
	channel and another process accepts a message on the same named channel. 

	\begin{Exa}
	\label{ex:simple_procs}
	\begin{align*}
			\mathrm{P} \defeq & coffee \ccsdot 0 \\
			\mathrm{Q} \defeq & \out{coffee} \ccsdot 0 
	\end{align*}	
	\end{Exa}
				
	In Example~\ref{ex:simple_procs} above the process \proc{P} listens on the 
	\channel{coffee} channel while process Q sends on it. A process that is 
	sending or receiving on a particular channel is blocked until another process
	performs the opposite operation on the channel. A synchronization happens 
	between one sender and one receiver, if two processes had been ready to 
	receive on the \channel{coffee} channel at the same time then one of them 
	would be chosen and the other would remain blocked. Channels are often given 
	descriptive names to indicate their purpose, in the example above we read it 
	as \proc{P} receives coffee from \proc{Q}. However, values can also be 
	passed along channels, and can then be bound to variables in the receiving 
	process. An example of this is shown in Example~\ref{ex:value_passing} below.
	
	\begin{Exa}\label{ex:value_passing}
	\begin{align*}
			\mathrm{Teacher} \defeq & \out{grade(12)} \ccsdot 0 \\
			\mathrm{Student} \defeq & grade(x) \ccsdot 0 
	\end{align*}	
	\end{Exa}

	In this example the \proc{Teacher} process sends the value 12 on the 
	\textsf{grade} channel. The \proc{Student} process receives the message on 
	the channel and binds the value to a variable $x$ which can then be used in 
	the continuation of the process.
	
	\textbf{Action prefixing} is how sequential processes are built up. A 
	process is prefixed with an action, meaning that first an action is 
	performed and then the process continues as the prefixed process. The syntax
	for this is generally a dot between the action and the following process. An 
	example of action prefixing is $a \ccsdot P$, here action $a$ is performed
	and then the process continues as \proc{P}. \proc{P} itself could also be an
	action prefixed process, it is straightforward to see how this can be
	expanded into a series of actions, e.g. 
	$\channel{a} \ccsdot \channel{b} \ccsdot \out{c} \ccsdot \proc{P}$. The 
	final process \proc{P} could either be the \textit{nil process} or a
	\textit{process constant}, which is further explained below.

	\textbf{Process constants} are labels given to particular processes to 
	identify them. In Example~\ref{ex:value_passing} we saw two examples of 
	process constants, \proc{Teacher} and \proc{Student}. These constants can 
	then be used in process descriptions to indicate that a given process turns 
	into another process. In Example~\ref{ex:process_constants} we see that a 
	\proc{CoffeeMachine} process first accepts a \channel{coin}, then outputs a 
	\channel{coffee} and then turns back into a \proc{CoffeeMachine} process. 
	This can be expanded into an endless series of 
	$coin \ccsdot \out{coffee} \ccsdot coin \ccsdot \out{coffee} \ccsdot coin \ccsdot \out{coffee}$ 
	etc. Recursive process definitions like these are used instead of looping 
	constructs which process languages generally do not have.  Of course, the 
	\proc{CoffeeMachine} process could just as well have turned into any other 
	process at the end, it does not have to only turn into itself.
	
	\begin{Exa}\label{ex:process_constants}
	\begin{align*}
			\mathrm{CoffeeMachine} \defeq & coin \ccsdot \out{coffee} \ccsdot \mathrm{CoffeeMachine} 
	\end{align*}	
	\end{Exa}

	\textbf{Nondeterministic choice} is a method for processes to choose between 
	two or more actions that the process can perform. The process is free to 
	choose arbitrarily which action to take. Example~\ref{ex:non_determinism} 
	shows how process \proc{P} can perform one of actions \channel{a}, 
	\channel{b} or \channel{c}. The choice is not made until at least one of the 
	channels has a corresponding process outputting on it that the choosing 
	process can synchronize with. There is no guarantee that the probability 
	between choices is fair, a recursive process might choose \channel{a} every
	time, or might make each choice exactly 33\% of the time.
		
	\begin{Exa}\label{ex:non_determinism}
	\begin{align*}
			\mathrm{P} \defeq & a \ccsdot 0 + b \ccsdot 0 + c \ccsdot 0
	\end{align*}	
	\end{Exa}
	
	\textbf{Restriction} hides channel events within a process from the outside 
	world. This can be used to simulate a machine that has internal workings 
	which are restricted, and a public interface which external processes can	
	synchronize with. Example~\ref{ex:restriction} shows a process P that hides 
	the channel \channel{a}. That means that the two parallel processes that $P$ 
	is composed of can only synchronize with each other on the \channel{a} 
	channel, not with an outside process. The \textit{observable} behaviour of 
	$P$ is that it only outputs on the \channel{b} channel and then terminates.
	
	\begin{Exa}\label{ex:restriction}
	\begin{align*}
			\mathrm{P} \defeq & (a \ccsdot 0 \paral \out{a} \ccsdot \out{b} \ccsdot 0)  			
	\end{align*}	
	\end{Exa}

	\textbf{Re-labelling} is a way to create general processes and make them 
	more specific by substituting their channel names with other channel names. 
	Consider for example the \proc{CoffeeMachine} process in 
	Example~\ref{ex:process_constants}. We can see that this is really a 
	specific version of a vending machine. To enable re-use for different types 
	of vending machines we could create a generic \proc{VendingMachine} process 
	that dispenses items, and create specific vending machines by re-labelling 
	those items to specific products. A re-worked example of a 
	\proc{CoffeeMachine} is shown in Example~\ref{ex:relabelling} where 
	\channel{item} is re-labelled to \channel{coffee}.
	
	\begin{Exa}\label{ex:relabelling}
	\begin{align*}
			\mathrm{VendingMachine} \defeq & coin \ccsdot \out{item} \ccsdot \mathrm{VendingMachine} \\
			\mathrm{CoffeeMachine} \defeq & \mathrm{VendingMachine}_{[coffee/item]}
	\end{align*}	
	\end{Exa}
	
	
\section{The .NET Framework}

\subsection{Overview and history}
	The .NET Framework is a framework from Microsoft for writing software 
	applications. It consists of a virtual machine that runs programs coded 
	specifically for the framework and a large standard library for application 
	developers to use when writing their applications. In addition, two 
	programming languages are included in the default distribution of the 
	framework, C\# and Visual Basic.NET. (A third language, J\#, was included in
	earlier versions but has since been dropped).

	The original name for .NET was Next Generation Windows Services (NGWS) and 
	its development started in the late 1990's at Microsoft. In late 2000 the 
	first beta versions of .NET 1.0 were released, and the first official 
	version of the .NET framework, 1.0, was released on February 13th, 2002. As 
	of this writing there have been five major releases of the framework, 1.0, 
	1.1, 2.0, 3.0 and 3.5. With each new version additional features have been 
	added, but not always in the way you would expect. The first three versions, 
	1.0, 1.1 and 2.0 all contained new versions of the virtual machine, new 
	versions of the compiler for the standard languages and additional 
	libraries. However, version 3.0 of the framework contained only new 
	libraries but no new compilers or new version of the virtual machine. 
	Version 3.5 then included new versions of C\# and Visual Basic.NET and some 
	additional libraries, but again no change to the virtual machine. As a 
	result, the version numbers of the different components of the framework 
	have diverged so when we talk about version 3.5 of the framework, that 
	includes version 3.5 of the libraries, version 2.0 of the virtual machine 
	and version 3.0 of the C\# language. 

\subsection{Common Language Infrastructure}

	The Common Language Infrastructure (CLI) is an open specification developed 
	by Microsoft that describes an executable code and runtime environment. This 
	is Microsoft's specification of the .NET framework, but it has been 
	published under ECMA-335 and ISO/IEC 23271 and so anyone is free to write 
	their own version that follows this specification. Two main alternate 
	versions exist, Mono and DotGNU. Both of these are released under open 
	source licenses and work on multiple operating systems, as opposed to 
	Microsoft's .NET which only runs on the Windows family of operating systems. 
	Microsoft has also released a shared source reference implementation of the 
	CLI specification. None of these other implementations fully implement all 
	the class libraries of the original .NET framework, and typically are about 
	one version behind Microsoft's .NET framework.

	The five main components described by the CLI specification are as follows:

	\begin{enumerate}
		
		\item \textbf{The Common Type System (CTS):} a set of types and operations 
		that are shared by all CLI-compliant programming languages.
		
		\item \textbf{Metadata:} Any CLI language can access code written in any 
		other CLI language. To achieve this, information about program structure 
		is language agnostic.
	
		\item \textbf{Common Language Specification (CLS):} A set of base rules to 
		which any language targeting the CLI should conform in order 
		tointeroperate with other CLS-compliant languages. The CLS rules define a 
		subset of the Common Type System.
	
		\item \textbf{Virtual Execution System (VES):} The VES is the component 
		that loads and executes CLI-compatible programs. 
	
		\item \textbf{Common Intermediate Language (CIL):} An intermediate 
		language that is abstracted away from the platform hardware. Upon 
		execution, the platform-specific VES will use a Just-in-time (JIT) 
		compiler to compile the CIL to hardware specific assembly language. Common 
		Intermediate Language is often referred to under the names MSIL (Microsoft 
		Intermediate Language) or simply as .NET bytecode.

	\end{enumerate}
    
\subsection{Languages}
	
	Two programming languages are included in the .NET default distribution. 
	Those are C\# and Visual Basic.NET. C\# derives its syntax from the C family 
	of languages, and in its first version was almost identical to the Java 
	programming language. Later versions have acquired a number of new features 
	such as lambdas, anonymous delegates and generators. In theory all .NET 
	languages are created equal; in practice C\# is first among equals, and the 
	entire standard library is for instance written in C\#. 

	Visual Basic.NET derives from the Basic family of languages. It has more 
	verbose syntax than C\# and is the continuation of Microsoft's Visual Basic 
	6 language. Visual Basic.NET has a number of differences from previous 
	version of Visual Basic though, mainly to fit into the .NET mold. To ease 
	the transition from Visual Basic 6 to Visual Basic.NET, Microsoft included a 
	number of old Visual Basic functions with the .NET framework in the 
	namespace Microsoft.VisualBasic. 
	
	In addition to these two main languages, there are dozens of other 
	languages that have implementations targeting .NET. These include well 
	established languages such as C++, Delphi, Lisp, Scheme, Smalltalk, Java 
	(in J\#), Python, Cobol, Ruby and JavaScript as well as languages that have 
	been built for .NET from the start, such as F\#, Nemerle and Boo.

\subsection{Virtual machine}

	The virtual machine, of the .NET framework is named the Common Language 
	Runtime (CLR). It manages the runtime requirements of programs written for 
	.NET and frees the programmer from having to consider specific machine 
	architectures or CPU's, as far as the programmer is concerned the CLR is the 
	(virtual) machine architecture that they are targeting. The CLR also 
	provides other runtime services such as security, exception handling and 
	memory management. Of these, perhaps the most important service provided is 
	memory management, which frees the programmer from allocating and 
	de-allocating memory at runtime. Some of the most common programming errors 
	in languages without memory management, such as C++, have to do with failing 
	to de-allocate memory, causing memory leaks, or accessing memory incorrectly 
	which in turn causes segmentation faults. Programs written for .NET eschew 
	this class of errors completely.
	
	The CLR executes programs that have been compiled to the Common Intermediate 
	Language (CIL) format. It is a stack based virtual machine, which means it 
	has an evaluation stack where the CIL bytecodes are evaluated. An 
	illustrative snippet of C\# code and it's corresponding CIL is shown in 
	Figure \ref{fig:cil}. The CIL bytecodes generally fall into four categories:
		
	\begin{enumerate}
		\item \textbf{Load items onto the stack}. These include bytecodes to load
		integers, floating point numbers, strings, object references, local 
		variables or class fields onto the evaluation stack. These bytecodes take 
		one argument each, the item to be loaded onto the stack.
		
		\item \textbf{Store stack items into variables/fields}. These bytecodes 
		take the top item on the stack and store it in a local variable, global 
		variable or class member variable. They take one argument, which is a 
		reference to the variable to store in.
		
		\item \textbf{Call functions}. These take an argument, that is a reference 
		to the function to call, and then call it with the parameters that are 
		currently on the evaluation stack.
			
		\item \textbf{Operate on stack items}. These bytecodes usually do nottake 
		any arguments, they simply use values on the stack and push results back 
		onto the stack. Examples of these are bytecodes that add, multiply or 
		divide the top two values on the stack, and then push the result back onto 
		the stack.
		
	\end{enumerate}
	
	At the time of execution, the CLR generates native code for the particular 
	machine architecture that it is running on from the CIL bytecodes, this is 
	referred to as Just-in-time compiling, or JIT compiling. A more detailed 
	explanation of that process is outside the scope of this paper, but detailed
	information can be found in \TODO{NEEDREF}.
	
\lstset{language=CSharp}
\lstset{commentstyle=\textit}
\begin{lstlisting}[frame=trbl]
using System;
namespace CodeGenDemo {
    class Program {
        static void Main(string[] args) {
            Console.WriteLine("Hello world");
        }
    }
}

-------------------------------------------------
.class private auto ansi beforefieldinit CodeGenDemo.Program
       extends [mscorlib]System.Object
{
  .method private hidebysig static void  Main(string[] args) cil managed
  {
    .entrypoint
    // Code size       20 (0x14)
    .maxstack  8
    IL_0000:  nop
    IL_0001:  ldstr      "Hello world"
    IL_0006:  call       void [mscorlib]System.Console::WriteLine(string)
    IL_0013:  ret
  } // end of method Program::Main
\end{lstlisting}
  
