\chapter{Process Language Runtime}

	This chapter presents the design and implementation of the Process Language 
	Runtime, an extensible compiler backend and a runtime library for running 	
	process languages on the .NET platform. 

\section{Inspiration}

	The inspiration for the Process Language Runtime comes from the Dynamic 
	Language Runtime \TODO{NEED REF} (DLR), a framework from Microsoft for 	
	developing dynamic languages on top of the Common Language Runtime. Since 
	the .NET Common Intermediate Language is statically typed it is ill-suited
	for dynamic languages such as Python, Ruby or JavaScript. To clarify, 
	statically typed languages are languages where the type of a variable is 
	known at compile time and the type of a variable never changes, while in a 
	dynamically typed language a single variable can contain objects of 	
	different types at different times during program execution. The idea of 
	having a common abstract syntax tree for different languages comes from the 
	DLR. However, the DLR was not directly used for this project since its 
	abstract syntax tree is mainly concerned with traditional constructs for 
	imperative programming languages and constructs to support dynamic typing, 
	while the purpose of this project is to provide constructs common to process 
	languages, and dynamic typing is not an issue we are concerned with.

\section{Overview}

	The PLR is a single .NET assembly, named PLR.dll. This assembly contains the 
	abstract syntax tree and associated helper objects as well as all the 
	classes used at runtime. The PLR does not contain any lexer or parser and 
	generally has no notion of any concrete syntax. Creating a lexer and parser 
	is the responsibility of individual language implementations, the PLR takes 
	over once an input file has been parsed and used to construct a PLR abstract 
	syntax tree. 
	
	It is important to note that the PLR does not, nor is it meant 
	to, support all constructs of all process languages. Creating a superset of 
	all existing process languages has never been the goal, instead the goal is 
	to provide a common subset of the most common constructs found in these 
	languages and to make it easy to extend with specific new constructs needed 
	for specific languages. To enable this, the classes and interfaces in the 
	PLR have been engineered to make them easy to subclass and implement.
	
	As the PLR contains classes needed at runtime it must be distributed with 
	any compiled process language application. However, an option is present in 
	the compilation stage that allows the PLR assembly to be embedded in the 
	final compiled executable program, and can optionally embed any additional 
	runtime libraries that specific languages require. This allows a process 
	language program to be distributed as a single file without any external 
	dependencies other than the .NET framework itself.

	The PLR itself is written in the C\# programming language using Visual 
	Studio 2008 as the development environment. It has a dependency on the NUnit 
	unit test framework, however this dependency is only needed when running 
	internal unit tests and so does not need to be distributed with the PLR 
	assembly. The source code for the PLR is licensed under the General Public 
	License (GPL) v3.0.
	
\section{Abstract Syntax Tree}

	The PLR abstract syntax tree is the component that generates CIL 
	bytecode to run a process language application. Once an abstract syntax tree 
	has been constructed, a call to a \code{Compile} method on the tree's root 
	node with the appropriate parameters will create an executable .NET 
	assembly. 

\subsection{Architecture}

	The architecture of the abstract syntax tree is based on Object Oriented 
	principles, namely that an object contains data and methods to operate on 
	that data. As such, each node in the abstract syntax tree knows how to 
	compile itself, there is no compiler class, the whole syntax tree is the 
	compiler. Every node in the syntax tree inherits from an abstract 
	\code{Node} base class which has an abstract \code{Compile} 
	method. Concrete node classes override the \code{Compile} method and in it 
	emit the appropriate byte codes for the language construct that the node 
	represents. 
	
	The compilation itself is recursive, calling the \code{Compile} method 
	on the root node of the tree will cause it to call the \code{Compile} 
	method of its child nodes, who in turn call \code{Compile} on their child 
	nodes and thus the compilation propagates throughout the entire tree. The 
	reason for choosing this architecture was to make the syntax tree easily 
	extendable by language implementors, who can add new nodes to represent new 
	constructs. 
	
	Concrete nodes typically do not inherit directly from the \code{Node} base 
	class, instead they inherit from one of five intermediate classes, 
	\code{Action}, \code{Process}, \code{Expression}, 
	\code{ActionRestrictions} or \code{PreProcessActions}. Below is a short 
	overview of what each of these classes represents.
	
	\code{Action} represents an action taken by the 
	process. This can for instance be sending on a channel, receiving on a 
	channel or calling an arbitrary method. Concrete descendants of this class 
	typically have either no child nodes of their own, or a list of 
	\code{Expression} nodes, representing parameters to a method call or 
	values passed through a channel.

	\code{Process} is the base class for processes. Its descendants include an 
	\code{ActionPrefix} class, a \code{NonDeterministicChoice} class and a 
	\code{ParallelComposition} class. Implementing a new language construct 
	such as replication could be done be creating a new descendant of this 
	class. Child nodes of \code{Process} classes vary, the 
	\code{ActionPrefix} class for example has one \code{Action} child node 
	representing the action about to be performed and one \code{Process} child 
	node representing the process that the current process turns into after 
	performing the action. Processes that are a composition of other processes 
	such as \code{ParallelComposition} and \code{NonDeterministicChoice} 
	have a list of other \code{Process} instances as childnodes.
	
	\textbf{Expression} represents an expression such as an arithmetic 
	expression, numeric or string constant, a method call or the value of a 
	variable.	Expressions compile in such a way that once they have been 
	evaluated a single value, the result of the expression, is at the top of the 
	evaluation stack. This means that a node that has an expression as a child 
	node can simply call the \code{Compile} method on the expression and then 
	emit bytecodes that operate on its result, without caring whether the 
	expression is a huge expression tree or a single constant value. An example 
	of this is the \code{ArithmeticExpression} node. In its \code{Compile} 
	method it first calls the \code{Compile} method of its left child, then 
	its right child and then emits an \code{Add},\code{Sub},\code{Mul} or 
	\code{Div} bytecode. The child nodes of \code{Expression} nodes are 
	invariably \code{Expression} nodes themselves.

 	\textbf{ActionRestrictions} represents a function that restricts actions 
 	within a process from synchronizing with other actions outside the process. 
 	This is an implementation of the \textit{restriction} process language 
 	construct described in Section~\ref{sec:common_constructs}. It currently has 
 	two concrete descendants. One is \code{ChannelRestrictions} which 
 	restricts channels by name, provided that the names of channels to restrict 
 	are known at compile time. The other is \code{CustomRestrictions}, that 
 	calls a .NET method at runtime for every action and returns \texttt{true} it 
 	it should be restricted. The method can be written in any language available 
 	for the .NET framework, the only requirements are that it takes an 
 	\code{Action} object from the PLR runtime library as a parameter and 
 	returns a boolean value.
	 
 	\textbf{PreProcessActions} represents a function that is called for every 
 	action that is performed in a process and returns another action. This is 
 	used to implement the \textit{re-labelling} process language construct 
 	described in Section~\ref{sec:common_constructs}. Simple re-labelling of 
 	channels with names known at compile time is done with a 
 	\code{RelabelActions} class. It has the names to re-label as child nodes 
 	and compiles down to a method that takes in an \code{Action} runtime class 
 	and performs simple string substitution on its name. More complicated 
 	pre-processing of actions can be achieved with another descendant class, 
 	\code{CustomPreprocess}. That class compiles down to a method call to a 
 	.NET method that takes an \code{Action} as a parameter and returns an 
 	\code{Action} as well. This method can be written in any language 
 	available for .NET.
 	
 	Besides all the descendant classes of those five main classes, there are a 
 	few classes that inherit directly from the \code{Node} class. 
 	\code{ProcessSystem} is the root node of the entire syntax tree and has a 
 	more complicated \code{Compile} method than most other nodes, since it 
 	takes care of setting up the necessary context for the compilation and 
 	creating the actual compiled file, giving it a name and so forth. 
 	\code{ProcessDefinition} is a simple class that just has a 
 	\code{Process} child node and a name for the process. Finally, 
 	\code{ExpressionList} is a convenience class to hold a list of 
 	\code{Expression} instances.
 	
	We now look at a simple example of a coffee machine, CM. The coffee machine 
	accepts a coin as input, then outputs coffee and then makes a non 
	deterministic choice between turning into itself again or turning into a 
	process representing a failure of the coffee machine, CMFAIL. The CMFAIL 
	process accepts a coin and then turns into the nil process without ever
	returning coffee for the inserted coin.

	\begin{Exa}
	\label{ex:coffee_machine_syntax}
	\begin{align*}
			\mathrm{CM} \defeq & coin \ccsdot \out{coffee} \ccsdot (\mathrm{CM}+\mathrm{CMFAIL})\\
			\mathrm{CM} \defeq & coin \ccsdot \mathrm{0}
	\end{align*}	
	\end{Exa}

	The syntax tree for the processes in Example~\ref{ex:coffee_machine_syntax} 
	is shown in Figure~\ref{fig:syntax_tree_example}. The names shown in 
	boldface are the names of the node classes, while the text in 
	parentheses shows properties of the nodes. Note that although this 
	particular tree is strictly binary it does not mean that all PLR trees
	are binary trees. \code{ProcessSystem}, \code{ParallelComposition} and 
	\code{NonDeterministicChoice} nodes can all have 1-n child nodes.
	
	
	\begin{figure}[h!]
		\centering
		\includegraphics[scale=0.7]{syntax_tree_example.jpg}
		\caption{PLR abstract syntax tree}
		\label{fig:syntax_tree_example}
	\end{figure}
 	

\subsection{Processing the syntax tree before compilation}\label{sec:visitor}
	
	There are many reasons why a language implementation might need to process 
	the abstract syntax tree in some way before compilation. An example might be 
	optimization; to fold constant expressions or prune branches of the tree 
	that are sure to never be executed. To support scenarios like this, the PLR 
	makes use of the \textit{Visitor} design pattern. The pattern is a way of 
	separating an algorithm from an object structure upon which it operates. As 
	a result, new operations can be added to existing object structures without 
	modifying those structures. A visitor interface contains one \code{Visit} 
	method for each of the classes in the object structure, each class in the 
	object structure then contains an \code{Accept} method that takes the 
	visitor interface as a parameter and does nothing except call the visitor's 
	\code{Visit} method with itself as a parameter. An example of this is 
	shown in Figure~\ref{fig:visitor_example}. This technique, calling the 
	objects \code{Visit} methods that immediately calls the visitors 
	\code{Accept} methods is known as \textit{double dispatch}. This 
	essentially mimics virtual method overloading, but the added benefit is that 
	the methods can be defined outside the object structure, making it easy to 
	plug in different implementations of the visitor as needed. The visitor 
	class can then contain different implementations of traversing the object 
	structure while calling the \code{Accept} method on each of its nodes. A 
	more detailed explanation of the visitor pattern and its benefits 
	can be found in \cite{design_patterns, visitor}.
	
	\begin{figure}
	\begin{csharp}
  
//Each node in the tree contains this method
public override void Accept(AbstractVisitor visitor) {
  visitor.Visit(this);
}
  
//The Visit method for ActionPrefix node in a subclass
//of AbstractVisitor. 
public override void Visit(ActionPrefix node) {
  //...process the ActionPrefix node here
}
\end{csharp}
\caption{Examples of Visit and Accept methods}
\label{fig:visitor_example}
	\end{figure}
  
  The PLR contains an \code{AbstractVisitor} class which is the base class
  of all visitor implementations. This was implemented as an abstract class
  rather than an interface for convenience reasons; the 
  \code{AbstractVisitor} provides empty implementations of the \code{Visit}
  method for each of the nodes in the abstract syntax tree, subclasses only
  need to override the \code{Visit} methods for nodes which they
  are interested in processing. Depth first traversal is a very common method
  of working with tree structures, to account for that common case the 
  \code{AbstractVisitor} contains a \code{VisitRecursive(Node node)} 
  method which performs a depth first recursive traversal of the tree, calling 
  each nodes \code{Accept} method along the way. A  boolean property on the 
  \code{AbstractVisitor} named \code{VisitParentBeforeChildren} controls 
  whether the parent or child nodes \code{Accept} methods are called first 
  during the traversal.  
  
  Process algebras are the subject of many academic papers, and it is likely 
  that future users of the PLR might be in the process of writing research 
  papers themselves. For that reason it could be quite useful to be able to 
  get a text representation of the abstract syntax tree, formatted in the
  LaTeX typesetting format (it certainly has been very useful for this 
  author!). The PLR contains three different formatter classes that generate 
  text representations of the syntax tree in different formats. 
  
  \begin{itemize}
  	\item \code{BaseFormatter} generates unformatted process algebra text, 
  	using the common symbols for constructs like non deterministic choice and 
  	parallel composition. 
  	
  	\item \code{LaTeXFormatter} generates LaTeX source, suitable for copying 
  	directly into a LaTeX document.
  	
  	\item \code{HTMLFormatter} generates HTML formatted text, suitable for 
  	displaying on the web.
  \end{itemize}
  
  The concrete syntax used by all of these formatters is that of CCS, however, 
  since many of the common process algebras use the same symbols for things 
  such as parallel composition and non deterministic choice, formatters for 
  other languages could be implemented simply by inheriting from one of the 
  three aforementioned classes and overriding the formatting methods only for 
  those constructs whose syntax differs from CCS syntax.
  
  The formatter classes are all implemented using the visitor pattern. The 
  benefits of the pattern here are obvious, it is easy to add new formats at a 
  later date without having to alter anything in the syntax tree itself, all 
  code for a particular format is kept in one place and formatter classes do 
  not need to implement tree traversal algorithms themselves.

	Figure~\ref{fig:expression_folder} shows another example of how the 
	visitor pattern can be useful. It is a class that takes binary 
	expressions that contain constants on both the left and right hand side, 
	calculates their results and replaces the \code{ArithmeticBinOpExpression} 
	node (which contains two child nodes) with a single \code{Number} node 
	containing the result of the expression. The code listing shows the entire 
	\code{ExpressionFolder} class, all it needs to do is inherit from 
	\code{AbstractVisitor} and override the \code{Visit} method that takes 
	\code{ArithmeticBinOpExpression} as a parameter. The visitor is executed 
	by calling \texttt{folder.VisitRecursive(tree)} where \texttt{folder} is an 
	instance of \code{ExpressionFolder} and \texttt{tree} is any \code{Node} 
	in the syntax tree, usually the root. Note that the folding only happens if 
	both the left and right node are \code{Number} nodes, however, the fact 
	that the tree is traversed depth first and child nodes are visited before 
	parent nodes ensures that even deeply nested expressions are folded as much 
	as possible. The leafs are visited first and folded if possible, by the time 
	the upper level nodes in the expression tree are visited they will have 
	\code{Number} nodes as children where previously were
	\code{ArithmeticBinOpExpression} nodes, and thus they can be replaced 
	as well. (Of course this example is fairly contrived, it is hard to think of
	a legitimate reason for writing down a large expression where all elements
	are constants. It does however show how the visitor pattern can be used to 
	implement classes that alter the syntax tree with a minimal amount of code).
	
	\begin{figure}[h!]
	\begin{csharp}
class ExpressionFolder : AbstractVisitor{

  public override void Visit(ArithmeticBinOpExpression exp) {
    if (exp.Left is Number && exp.Right is Number) {
      int result = 0, leftVal, rightVal;
      leftVal = ((Number)exp.Left).Value;
      rightVal = ((Number)exp.Right).Value;
		
      if (exp.Op == ArithmeticBinOp.Plus) {
        result = rightVal + leftVal;
      } else if (exp.Op == ArithmeticBinOp.Minus) {
        result = rightVal - leftVal;
      } else if (exp.Op == ArithmeticBinOp.Multiply) {
        result = rightVal * leftVal;
      } else if (exp.Op == ArithmeticBinOp.Divide) {
        result = rightVal / leftVal;
      }
      int pos = exp.Parent.ChildNodes.IndexOf(exp);
      exp.Parent.ChildNodes[pos] = new Number(result);
    }
  }
}
\end{csharp}
\caption{Expression folder implemented using Visitor pattern} \label{fig:expression_folder}
\end{figure}

\subsection{Extensibility}
	
	As stated before, one of the goals of the PLR is extensibility, allowing
	for language implementors to add features and constructs not included in
	the PLR itself. There are three main methods of extending the PLR. Firstly,
	language implementors can add new nodes to the abstract syntax tree. These
	nodes just have to implement the \code{Compile} method and then they can
	be seamlessly integrated with the built in PLR nodes. Of course it is also
	possible to inherit from one of the existing nodes and thereby re-using some
	of the compilation work they do, and simply adding extra code before or after
	the base classes compilation step. 
	
	Secondly, the root node of the abstract	syntax tree, \code{ProcessSystem} 
	exposes the following four events. 
	
	\begin{enumerate}
		\item \code{BeforeCompile} occurs before the PLR has performed any 
		compilation. At this point only the \code{AssemblyBuilder} and 
		\code{ModuleBuilder} have been defined, no types or methods exist yet.
		
		\item \code{AfterCompile} occurs after the PLR has finished all its
		compilation but before it creates the executable file. At this point
		subscribers to this event can access any types or methods created during
		compilation.
		
		\item \code{MainMethodStart} occurs just after the main method of the
		application has been defined but before any bytecodes have been emitted
		into it. Subscribers of this event can then inject their own bytecodes at 
		the beginning of the main method if they wish.
		
		\item \code{MainMethodEnd} occurs after all bytecodes of the main method
		have been emitted, except for the final \code{Ret} instruction. Again, 
		subscribers of this event can inject their own bytecodes at this point.
	\end{enumerate}
	
	All these events have the same signature, they require a 
	\code{CompileEventHandler} delegate, which takes a \code{CompileContext} 
	as a parameter. The event subscribers then use the compile context to create 
	types, methods and emit bytecodes at different points in the compilation 
	process.
	
	Finally, the third way to extend the PLR is to write supporting code in
	another .NET language, writing a seperate runtime library. The KLAIM 
	implementation described in Chapter~\ref{ch:klaim} takes this approach. When 
	a language implementation requires large amounts of supporting code it is 
	inconvenient and error prone to generate all that code by emitting CIL 
	bytecode at compilation time. By creating a runtime library instead, 
	language implementors can get the benefit of programming languages and tools 
	such as C\# and Visual Studio when writing the common, re-usable parts of 
	their languages. Then, at compilation time, they can simply emit bytecodes 
	to call code in the runtime library. This is also the approach taken by the 
	PLR itself, which has runtime classes written in C\# and emits bytecodes 
	during compilation that interact with these classes.	

\subsection{Code generation}
	
	To generate a valid .NET assembly the PLR uses a set of classes that are a 
	part of the .NET framework Base Class Library. These classes are located in 
	the \code{System.Reflection.Emit} namespace. Before explaining more about 
	these classes it is worth going over how a .NET assembly is structured. A 
	.NET \textit{assembly} is an executable file (.exe) or a dynamic link 
	library (.dll). The assembly contains one more \textit{modules}, typically 
	just one. Each module contains one or more \textit{types} (or classes). 
	Types have \textit{fields}, \textit{constructors} and \textit{methods}. At 
	the lowest level, constructors and methods contain CIL bytecodes. 
	Figure~\ref{fig:assembly} shows the structure.

	\begin{figure}[h!]
		\centering
		\includegraphics{assembly2.jpg}
		\caption{The structure of a CIL assembly}
		\label{fig:assembly}
	\end{figure}
	
	The classes in the \code{System.Reflection.Emit} namespace match the 
	structure of an assembly. There is an \code{AssemblyBuilder}, 
	\code{ModuleBuilder}, \code{TypeBuilder}, \code{FieldBuilder}, 
	\code{ConstructorBuilder} and a \code{MethodBuilder}. These are instantiated 
	by giving them names and other properties as parameters. The 
	\code{ConstructorBuilder} and \code{MethodBuilder} have a 
	\code{GetILGenerator} method that returns an object of type 
	\code{ILGenerator}. That object has direct access to the bytecode stream of 
	the method being created, and contains various overloads of an \code{Emit} 
	method that emits bytecodes and their associated arguments. An 
	\code{OpCodes} class contains constants for all possible bytecodes that can 
	be emitted by the \code{ILGenerator}.
	
	The nodes of the syntax tree gain access to these classes through a 
	\code{CompileContext} class which is part of the PLR, and is a parameter 
	to the \code{Compile} method implemented by all nodes. The 
	\code{CompileContext} class has a number of useful properties that the 
	nodes can access. It exposes the \code{TypeBuilder} object of the type 
	currently being built, the \code{ILGenerator} object of the method or 
	constructor being built and a symbol table for variables currently in scope. 
	The node can then emit its bytecodes, create new variables or otherwise 
	alter the \code{CompileContext} before passing it on to its child nodes 
	\code{Compile} methods. Essentially this is a form of distributed 
	compiling, no one node has a complete picture of what is being compiled, 
	each node only has enough information to add its own code to the correct 
	type or method.

\subsection{Debugging support}\label{debug_support}
	
	One of the benefits of targeting a common virtual machine such as the CLR is
	is that both a free command line and graphical debugger exist that can be 
	used for any programming language that compiles down to the Common 
	Intermediate Language format. The \code{System.Reflection.Emit} API offers 
	functionality to emit the necessary debugging symbols to be able to use 
	these debuggers. Emitting debug symbols consists of the following five steps:
 	
 	\begin{enumerate}
 		\item When the \code{ModuleBuilder} objects is defined with a call to 
 		the \code{DefineDynamicModule} method on the \code{AssemblyBuilder} 
 		object, a parameter named \code{emitSymbols} should be passed as 
 		\texttt{true}.
 		
		\item An item of the type \code{ISymbolDocumentWriter} needs to be 
		defined. This is done with a call to a \code{DefineDocument} method on 
		the \code{ModuleBuilder} object which returns a 
		\code{ISymbolDocumentWriter} object. The parameters to this method call 
		include the name of the source file that is being compiled, this is 
		neccessary so that the debugger can prompt for the source file when 
		debugging the compiled file. The \code{ISymbolDocumentWriter} object is 
		passed with the \code{CompileContext} to all nodes during compilation.

		\item Local variables in methods are created with a \code{LocalBuilder} 
		object. In a non debug build these locals are not stored by name in the 
		compiled file, but simply given a number and referred to by that number.
		To be able to map variables in the compiled file to variable names in the
		source file a method, \code{SetLocalSymInfo} is called on the 
		\code{LocalBuilder} object. The method takes the name of the variable as
		a parameter and stores that information for later use by the debugger.
		
		\item The method \code{SetUserEntryPoint} must be called on the 
		\code{ModuleBuilder} object to enable the debugger to know what the entry
		method of the assembly is. The method takes a \code{MethodBuilder} object
		as a parameter.
		
		\item The most important part of emitting the debug symbols is marking 
		\textit{sequence points} in the CIL bytestream. A sequence point is a 
		point in the bytecode that tells the debugger to stop at that point during 
		code execution and highlight a particular section in the source code file. 
		To be able to do this the sequence point contains information about a 
		start position and end position in the source file, given as line and 
		column numbers. A sequence point is marked with a call to a 
		\code{MarkSequencePoint} method on an \code{ILGenerator} object, the 
		methods parameters are an instance of \code{ISymbolDocumentWriter} and 
		four integers, startLine, startColumn, endLine and endColumn. 
		Figure~\ref{fig:sequence_points} shows a few lines of CIL bytecode 
		interspersed with sequence points. (Note: the CIL file format does not 
		store sequence points in exactly this manner, the figure is simply meant 
		to clarify the concept). It is worth noting that the CIL has no notion of 
		statements, expressions or other programming language constructs, it is 
		perfectly legal to insert a sequence point in the middle of an expression
		or anywhere else in the bytecode. It is completely up to the programmer to
		insert sequence points at meaningful points in the bytestream according to
		the semantics of the language being implemented.
		
 	\end{enumerate}
 	
 	The PLR handles these five steps, so an implementation of a language that 
 	uses the PLR as its backend compiler does not need to concern itself with 
 	them directly. However, since the PLR does not handle parsing of source 
 	files it can not determine itself the line and column numbers needed for 
 	marking sequence points. For that purpose, every node in the PLR abstract 
 	syntax tree has an instance of a class named \code{LexicalInfo}. This 
 	class is simply a wrapper around the four integers that a sequence point 
 	needs, startLine, startColumn, endLine and endColumn. This information is 
 	easily available during parsing and so the individual language parsers 
 	should store this information for each node. The PLR will then automatically 
 	emit a sequence point before every \textit{action} taken by a process, as 
 	well as for expressions evaluated in \texttt{if-then-else} processes and for 
 	process invocations.

	\begin{figure}
	\begin{cil} 
.method private hidebysig static void  Main() cil managed
{
  .entrypoint
  // Code size       22 (0x16)
  .maxstack  8
  IL_0000:  nop
//debugger stops, highlights line 12, col 9-36
/*@\textbf{[SEQUENCEPOINT (12, 9, 12, 36)]}@*/
  IL_0001:  ldstr      "Hello"
  IL_0006:  call       void Program::WriteLine(string)
  IL_000b:  nop
//debugger stops, highlights line 13, col 9-26
/*@\textbf{[SEQUENCEPOINT (12, 9, 12, 36)]}@*/
  IL_000c:  ldc.i4.s   27
  IL_000e:  ldc.i4.4
  IL_000f:  call       void Program::Power(int32, int32)
  IL_0014:  nop
  IL_0015:  ret
} // end of method Program::Main
  \end{cil}
  \caption{CIL bytecode with sequence points}
  \label{fig:sequence_points}
	\end{figure}
	
\section{Runtime Library}

	The PLR has a small runtime library consisting of nine classes. These classes
	reside in the \code{PLR.Runtime} namespace. Applications compiled using 
	the PLR must have access to this library at runtime in order to execute 
	successfully. Figure~\ref{fig:runtime_library} shows a class diagram of the 
	runtime library. Below is an overview of each of the nine classes.

	\begin{figure}[ht!]
		\centering
		\includegraphics[scale=0.5]{RuntimeLibrary.png}
		\caption{PLR runtime library classes}
		\label{fig:runtime_library}
	\end{figure}

	\textbf{ProcessBase} is an abstract base class for any compiled processes.
	It contains methods used to interact with the \code{Scheduler},
	for instance method to synchronize on channels, methods for startup and
	termination as well as methods to suspend and resume the process thread.
	Since processes are built up into a tree-like structure at runtime (further 
	explained in Section~\ref{sec:cil_architecture}) it also contains a field 
	for its parent \code{ProcessBase} instance. Finally, it contains a list of 
	\code{IAction} instances, this list will hold all actions that occur in 
	the process instance or any of its subprocesses and are restricted by the 
	instances restriction clause.
	
	\textbf{BuiltIns} is a small static class that contains utility methods
	that can be called by processes, such as to print to the console.
	
	\textbf{IAction} is an interface that all runtime actions must implement.
	It contains four methods. \code{ProcessID} returns the id of the
	process performing the action, \code{IsAsynchronous} returns true if
	the action can be executed without synchronizing with another action, 
	this applies for instance to arbitrary method calls to .NET methods.
	\code{CanSyncWith(IAction other)} determines whether the action can be 
	synced with another action, in the case of asynchronous actions this
	method always returns false. Finally, \code{Sync(IAction other)} is 
	called on those actions that have been chosen for execution and is used
	for example to pass values from one process to another through channels.

	\textbf{ChannelSyncAction} is a class representing synchronization on a
	channel. It contains the channel name, the id of the process performing
	the action and information about whether the process is attempting to send
	or receive on the channel. In the case of a send operation it can optionally
	contain a list of values that are being sent, and in the case of a receive
	operation it can contain a list of variables that should be bound to the 
	values being sent from the other side. The \code{ChannelSyncAction}
	implements the \code{IAction} interface as all runtime actions must, it is
	a synchronous action and its \code{CanSyncWith} method will only return 
	true for other \code{ChannelSyncAction} instance that have the same
	channel name, are performing the opposing operation and have the same
	number of values being passed through the channel. When two actions are
	synchronized, the \code{Sync(IAction other)} method on both the actions
	are called with the other actions as a parameter. In the case of channel 
	synchronizations the action instance which represents the receiving end
	of the operation will bind its variables to the values passed through
	the channel in its \code{Sync} method, the sending action will do nothing
	in its own \code{Sync} method.
	
	\textbf{MethodCallAction} is a runtime action which can be used to call
	an arbitrary .NET method, either a built-in method from the .NET base
	class library or a method from any .NET assembly. It is an asynchronous 
	action and as such does not need to synchronize with another process to be 
	executed. Currently	the PLR provides support for calling static methods 
	that have integers or	strings as parameters. This allows for instance most
	of the methods from the \code{System.Math} class to be accessible. To
	gain access to instance methods, for example the \code{NextInt} method
	of the \code{System.Random} class, it is necessary to write static wrappers
	around the methods.

	\textbf{Logger} is a utility class for handling process output to the screen.
	Its main feature is assigning a different color to each process to 
	easily distinguish between them in the console output.

	\textbf{GlobalScope} is a small class whose only purpose is to be a 
	repository of possible actions that are not restricted by any process. As
	explained in Section~\ref{sec:cil_architecture}, candidate actions are 
	propagated up the process tree, and at each process it is checked whether 
	the process restricts them, if so they are stored within that process so 
	that they do not synchronize with actions outside the process. In the case 
	where no process restricts the action and it can synchronize with any other 
	action that is not otherwise restricted then the action is stored in the 
	global scope, while it waits to see whether it was chosen for execution.
	
	\textbf{ProcessKilledException} is an exception class used when processes
	are killed. As an example, when a process is a candidate in non deterministic
	choice and is not chosen then it must be killed. To bypass all the subsequent
	actions of the process, a \code{ProcessKilledException} is thrown and then
	caught at the end of the processes code. There the process will unregister
	itself from the \code{Scheduler}, print a message to the console and then
	terminate.
	
	\textbf{Scheduler} is the real execution engine of the PLR. It follows the
	\textit{Singleton} \cite{design_patterns} design pattern so it is trivial 
	for all	processes in the application to gain access to the same 
	\code{Scheduler} instance. When processes are activated they register 
	themselves with the scheduler, which keeps a list of active processes. The 
	scheduler then monitors the processes and waits until all processes have 
	generated all their candidate actions and are waiting for an action to be 
	executed so they can continue. At that point the scheduler goes through all 
	the possible actions, figures out which actions can sync with each other and 
	then randomly chooses an action to execute. It then executes the action and 
	wakes up the processes involved in the action so that they can resume 
	execution. It also terminates certain processes (or rather instructs them to 
	terminate themselves). These are generally candidates of non deterministic 
	choice who were not chosen. Once the scheduler has finished one such round 
	it again waits until all the processes it woke up are again suspended and 
	then chooses the next action to execute, and so on. 
	Figure~\ref{fig:scheduler} shows the workings of the scheduler in 
	pseudocode. Other responsibilities of the scheduler are thread locking and 
	synchronization, and keeping track of the \textit{trace}, that is the list 
	of actions executed during the duration of the program.
	 
	\begin{figure}
	\begin{codeblock}
// active_procs contains all the running processes

do forever:
  all_blocked = true
  
  for every process p in active_procs
    if state(p) != STATE_BLOCKED
      all_blocked = false
    
  if all_blocked = true
    //Find matches...      
    candidate_matches = []
    for every process p in active_procs:
      //p.restricted_actions contains those actions
      //being performed within p that are restricted 
      //by p and so can not go into the global_scope 
      //and sync with any other action
      for every action a in p.restricted_actions
        for every action b in p.restricted_actions
          if a can sync with b
            candidate_matches.add( (a,b) )
		
    for every action x in global_scope
      for every action y in global_scope
        if x can sync with y
          candidate_matches.add( (x,y) )
    
    if length(candidate_matches) = 0
    	DEADLOCK, program finishes
    else
      set match = random(candidate_matches)
      execute(match)
      wake up processes that had actions in the match
      kill processes that were not selected 
        in non deterministic choice
	
	\end{codeblock}
	\caption{The scheduler algorithm}
	\label{fig:scheduler}
	\end{figure}
	

\section{CIL Structure of a Process Language Application}\label{cil_structure}

	A process language application is in many ways different from an application
	written in a traditional programming language. One of the goals of this  
	project was to investigate how well process languages are suited to the .NET
	virtual machine. We now look at how a process language system looks once it 
	has been compiled to the Common Intermediate Language.
	
	\subsection{Architecture choices}\label{sec:cil_architecture}
	One of the hardest decisions during the design of the PLR was whether or not 
	to represent each process as a separate thread. Writing multi-threaded code 
	is hard, and it is subject to subtle errors, race conditions and other 
	problems that are easily avoided when using only a single thread. However, a 
	single threaded implementation would be forced to represent the processes as 
	datastructures, rather than as independent programs in their own right. 
	That approach, that the processes are datastructures and the program is a 
	single thread operating on those datastructures is certainly worthwhile, and 
	in fact an early prototype was implemented as an interpreter that did just 
	that. It even makes certain things easier, such as the visualizing the state 
	of the processes after each round. However, using multiple threads allowed 
	for compiling each process relatively independently of other processes, and 
	conceptually seemed closer to the semantics of process algebra. Another
	benefit of the multi-threaded approach was that it made emitting debug 
	symbols fairly simple, while doing the same in a single threaded way would 
	have been problematic. For these reasons the multi-threaded approach was 
	taken.
	
	Another concern when deciding how to structure a process language 
	application was the semantics of restriction and relabeling. When these are 
	applied to a process they keep applying to any subsequent process that it 
	may invoke. E.g. in $(a . P)[d/c]$ the relabeling of $c$ to $d$ has to be 
	applied to everything that happens in the invoked process $P$. To handle 
	this each process has a reference to the process that spawned it in a 
	\code{Parent} property. At runtime $P$ would have $(a . P)[d/c]$ in its 
	\code{Parent} property and whenever it performs an action it will first 
	check whether it restricts or relabels it itself, if not it will pass the 
	action up to its parent which can check again if the action is restricted at 
	that level, and and so it propagates up the chain of parent processes. If an 
	action is restricted at a particular level then it can only synchronize with 
	other actions that are at the same level, those actions that are not 
	restricted at all go on up to the global scope, where they become observable 
	from the outside.
	
	The one problem with that approach is that a lot of processes do not 
	restrict or relabel anything at all, and would then be kept alive for no 
	reason, they would simply take up memory and make the process tree 
	unnecessarily complicated. To avoid this, processes only set themselves as 
	the parent of a spawned process if they actually have some restrictions or 
	relabellings. If they do not then they set their own parent as the parent of 
	their spawned processes. This is perhaps best explained by an example.
	
	\begin{verbatim}
			                      A = a . b . B
			                      B = (b . c . C) \{b,c}
			                      C = c . d . A
			                      D = 0
	\end{verbatim}
	
	In the system above the initial process is $A$. It performs two actions and 
	then turns into $B$. A is not restricted in any way so there is no reason 
	for it to set itself as $B$'s parent. A then checks if itself has a parent, 
	it does not and so it sets $B$'s parent to \code{null} before starting it.
	$B$ on the other hand is restricted, so after it has performed its actions 
	it starts $C$ and sets itself as $C$'s parent. When $C$ performs its $c$ 
	action it is passed up to its parent and is restricted in the $B$ process. 
	When $C$ eventually turns into $D$ it needs to decide what $D$'s parent will 
	be. $C$ itself has no restrictions and so does not need to live on, so it 
	sets $D$'s parent as its own parent, which was $B$. $C$ can now die and be 
	removed from memory, $D$ has $B$ as its parent so the restrictions of $B$ 
	will continue to be applied correctly.
	
	\subsection{Processes}
	Each process in process algebra maps to a class in CIL. The process classes 
	all inherit from a \code{ProcessBase} class in the PLR runtime library and 
	override a \code{RunProcess} method. When a process has been instantiated, a 
	\code{Run} method is called on it, and it will then run the 
	\code{RunProcess} method on a new thread.

	The top level processes, those that are defined as named process constants, 
	are compiled to classes named after the process constant. A top level class 
	can have multiple inner classes however, and each of those can itself have 
	multiple inner classes. This happens for instance when a process starts by 
	performing an action and then turns into a process that is a parallel 
	composition of 	other processes, e.g. $a \ccsdot (b \ccsdot 0 \mid c \ccsdot 
	0)$. In that case each of those parallel processes is an inner class of the 
	original top level process. The same thing happens when a process makes a 
	non-deterministic choice; each of the choices is its own inner class. The 
	reason for making these inner classes was that in a fairly large system the 
	number of classes quickly becomes large, and instead of polluting the top 
	level namespace with dozens of generated class names, they are confined 
	within their owning process. It is also easier to understand what each 
	process represents, the class name \code{PC+Parallel1} represents the 
	first parallel process within the \code{PC} process, which is a 
	parallel composition process. Figure~\ref{fig:struct_parallelcomp} shows the 
	assembly structure of a simple parallel composition process, $PC \defeq a 
	\ccsdot (b \ccsdot 0 \mid c \ccsdot 0)$. (This is a screenshot from a tool 
	called ILDASM from Microsoft, the large boxes with three pins represent 
	classes, the triangles represent metadata about the classes and the small 
	rectangles represent methods).
	
	\begin{figure}
		\begin{center}\includegraphics[scale=0.7]{ex_pc.png}\end{center}
		\caption{Assembly structure of process  $PC \defeq a \ccsdot (b \ccsdot 0 \mid c \ccsdot 0)$}
		\label{fig:struct_parallelcomp}
	\end{figure}
	
	The semantics of action prefixing ($a \ccsdot P$) state that action $a$ is 
	performed and the process then behaves like $P$. Considering how parallel 
	composition and non deterministic choice were implemented with inner classes 
	it might then seem natural to perform $a$ and then invoke an inner class 
	$P$. That is not the case however. The reason is that it is very common to 
	have a list of actions performed, e.g. $a \ccsdot b \ccsdot c \ccsdot d 
	\ccsdot P$, and creating a new class after every single action would result 
	in a large number of classes for no purpose. So for a process such as this, 
	all the actions are performed in the same class, in its \code{RunProcess} 
	method. There are exceptions to this however, if a process performs some 
	actions and then becomes another action prefixed process that is restricted 
	or has relabellings then it will have an inner class at that point. For 
	example the process $a \ccsdot b \ccsdot (c \ccsdot P) \backslash\{c\}$ will 
	perform actions $a$ and $b$ in the main class, but have an inner class for 
	$(c \ccsdot P) \backslash\{c\}$. The reason for this is that restrictions 
	and relabellings always have process scope, and since the restriction on $c$ 
	does not apply to the first actions $a$ and $b$ then a new process is needed 
	after $a$ and $b$ have been performed. Figure~\ref{fig:struct_actionprefix} 
	shows the assembly structure of the process $AP \defeq a \ccsdot b \ccsdot 
	(c \ccsdot P) \backslash\{c\}$. Note that the class \code{AP+Inner} 
	contains \code{get\_Restrict} and \code{RestrictByName} methods, while the 
	outer class \code{AP} does not.

	\begin{figure}
		\begin{center}\includegraphics[scale=0.75]{ex_ap.png}\end{center}
		\caption{Assembly structure of process  $AP \defeq a \ccsdot b \ccsdot (c 
	\ccsdot P) \backslash\{c\}$}
		\label{fig:struct_actionprefix}
	\end{figure}
	
	Process invocations, that is when a process turns into a named process, is 
	implemented simply by creating a new instance of the named process and 
	starting it. The process $c \ccsdot Proc$ performs action $c$ and then 
	creates a new instance of \code{Proc} and starts it, after that has been 
	done $c \ccsdot Proc$ simply exits, \code{Proc} has been started in its 
	place. The only complication here is if a restriction or relabeling is 
	applied to \code{Proc} but not the rest of the process. If the process was 
	written as $c \ccsdot (Proc \backslash\{a\})$ then an inner class would be 
	needed, whose only purpose was to create a new instance of \code{Proc} and 
	start it. This might seem a wasteful inner class, but keep in mind that this 
	restriction lives on and applies to everything that happens in \code{Proc} 
	and any other process that \code{Proc} might turn into. The instance of 
	\code{Proc} that is started will have a reference to the process $(Proc 
	)\backslash\{a\}$ in its \code{Parent} property, any action performed in 
	\code{Proc} will be passed up along the parent chain to see if it is 
	restricted or relabeled at some point.
	
	\subsection{Restrictions and relabellings}
	Restrictions and relabellings map to methods in CIL. The methods do not
	have to be member methods of a process class, there is an extra layer
	of indirection to allow for calling methods in external assemblies. The
	\code{ProcessBase} class has two methods, \code{get\_PreProcess} and 
	\code{get\_Restrict} \footnote{The odd naming stems from the fact that these 
	are defined as \textit{properties} in the \code{ProcessBase} class, where 
	they are named \code{Restrict} and \code{PreProcess}. Properties in C\# 
	simply compile down to getter and setter methods with get\_ and set\_ 
	prefixed to the property name)}. These methods return delegates (otherwise 
	known as function pointers) to a preprocess function (such as a relabelling 
	function) and a restriction function, respectively. The base class versions 
	of \code{get\_PreProcess} and \code{get\_Restrict} return function pointers 
	to methods that do not alter or restrict any actions. Concrete process 
	classes can override these methods and return function pointers to other 
	methods, either methods in the process class itself, or methods in some 
	external assembly. 
	
	\begin{figure}
		\begin{center}\includegraphics[scale=0.7]{ex_rr.png}\end{center}
		\caption{Assembly structure of process  $RR \defeq (a \ccsdot b \ccsdot c \ccsdot 0)_{[x/a,y/b]} \backslash \{ c \}$}
		\label{fig:struct_restrictrelabel}
	\end{figure}

	The PLR can compile simple restrictions and relabellings directly into the 
	class where they are used. (Simple meaning that they only use constant 
	channel names, like $[a/b]$ or $\backslash\{c,d\}$, and do not require any 
	additional logic). Figure~\ref{fig:struct_restrictrelabel} shows the 
	assembly structure of a simple restricted and relabeled process, $RR \defeq 
	(a \ccsdot b \ccsdot c \ccsdot 0)_{[x/a,y/b]} \backslash \{ c \}$. The 
	restriction method is named \code{RestrictByName} and the relabeling method 
	is named \code{RelabelAction}. The base class methods 
	\code{get\_Restrict} and \code{get\_PreProcess} have then been overriden to 
	return function pointers to \code{RestrictByName} and \code{RelabelAction}, 
	respectively.

	\subsection{Variables and scope}
	
	Variable scope becomes a bit tricky due to the possibly many inner classes
	of a single process. A simple process like $in(x) \ccsdot (\overline{out}(x) 
	\ccsdot 0)\backslash\{out\}$ is actually two classes and the $in$ and $out$ 
	actions are performed in different methods. The variable $x$ still needs to 
	be passed on so that the inner process has access to the value that was 
	bound in the outer process. An additional complication is that the processes 
	main logic has to be defined in an overridden method, \code{RunProcess}, so 
	changing the parameters of that method is not an option. And finally, a 
	variable may be bound and the process may then become two or more parallel 
	processes, each of which must have access to the variable. Consider the 
	process $in(x) . (\overline{left}(x) . 0 \mid \overline{right}(x).0)$. Both 
	of the parallel processes use the variable $x$, but an important thing to 
	note is that they each have their own instance of it. Changing it in one 
	parallel process does not affect it in another. This may seem 
	counterintuitive, but consider if changing the variable in one process did 
	affect it in the other process, then we would have created a new method of 
	communication between processes, shared variables!
	
	The PLR handles variables by passing them as parameters to the inner 
	processes constructor. The inner process then assigns each of the 
	constructor parameters to member variables. The PLR variables are either 
	integers or strings, integers are passed by value and strings are immutable, 
	so there is no danger of two processes changing the same value in memory. At 
	the start of a process's \code{RunProcess} method, it defines local 
	variables with the same names as its member variables and assigns the member 
	variables to local variables. This was done for two reasons, it simplifies 
	working with variables in the method since all variable lookups are done on 
	local variables (keep in mind that new local variables might also be 
	defined), and it helps during debugging, the debugger will display the value 
	of local variables when the mouse cursor hovers over their names.
	
  A process may split into many processes and not all of them might need to 
  use all variables. As an optimization, the PLR examines the syntax tree 
  during compilation and only defines member variables and constructor 
  parameters in processes where it is possible that the variable will be used 
  in the process. For example, in the process
  
  \begin{center}$\mathrm{VAR} \defeq in(x) \ccsdot in(y)\ccsdot (\overline{out}(x) \ccsdot 0 \mid \overline{out}(y) \ccsdot 0)$\end{center}
  
	the main $VAR$ process will define two local variables, $x$ and $y$. The 
	first parallel process, $\overline{out}(x) \ccsdot 0$, will have a 
	constructor with only one parameter, $x$ and one member variable $x$, the 
	second parallel process, $\overline{out}(y) \ccsdot 0$, will only have $y$ 
	as a member variable and constructor parameter.

\section{Summary}

	The Process Language Runtime is implemented as a .NET library, which 
	contains both the abstract syntax tree used during compilation as well as 
	runtime classes used during execution. The syntax tree is the most important 
	part of the PLR, it is a rich datastructure where each node knows how to 
	compile itself and emit the correct bytecodes. Debugging support is also 
	provided by the PLR, although individual language parsers must provide the 
	PLR with information about line and column numbers for the process 
	constructs. Implementers of process algebras can extend the PLR by creating 
	additional syntax tree nodes, subscribing to compilation events and writing 
	their own runtime libraries. When a process language system is compiled then 
	individual processes become classes in .NET, actions become method calls and 
	restrictions and relabellings are implemented as methods, with function 
	pointers used as an abstraction to allow for calling methods in external 
	assemblies.
  